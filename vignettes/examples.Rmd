---
title: "Examples of using survextrap"
author: "Christopher Jackson <chris.jackson@mrc-bsu.cam.ac.uk>"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_document:
    toc: true
    toc_float: true
    theme: simplex
    code_folding: show
vignette: >
  %\VignetteIndexEntry{Examples of using survextrap}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r,echo=FALSE,message=FALSE}
knitr::opts_chunk$set(eval=TRUE, message=FALSE, warning=FALSE)
```


```{r,echo=FALSE,message=FALSE}
rstan::rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```

This vignette gives examples of how to run `survextrap` to fit survival models.

See the [README](../index.html) for the design principles of the package, and the [methods vignette](methods.html) for technical details of the methods.

It is work in progress, so it will be sketchy in some places.   The code is supposed to work, but do not be surprised if there are bugs - please report any on [github issues](https://github.com/chjackson/survextrap/issues).

# Examples

For these examples, we use a dataset of trial of chemotherapy for colon cancer, provided as `colon` in the `survival` package, with an outcome of recurrence-free survival (`etype==1`), artificially censored at 3 years, and restricted to a random 20% subset.  This is provided as `colons` in the `survextrap` package for convenience.

```{r}
library(survextrap)
library(dplyr)
survminer::ggsurvplot(survfit(Surv(years, status) ~ 1, data=colons), data=colons)
```


## No external data

The following is the simplest, default model in the package fitted to the short-term trial data alone. No external data are supplied.  After three years (the maximum follow up time of the short term data) 
the model assumes the hazard stays constant.   

The plot shows the posterior median and 95\% credible intervals for the survival and hazard functions.  The spline adapts to give a practically perfect fit to the short-term data - note the Kaplan-Meier curve is obscured by the fitted posterior median.   Although the model assumes the extrapolated hazard is constant, there is still a wide uncertainty interval around this constant value.  This might be thought to be plausible.

```{r,results="hide"}
nd_mod <- survextrap(Surv(years, status) ~ 1, data=colons, chains=1)
plot(nd_mod, tmax=5)
```

The spline knots are shown as blue lines.  We could allow for the possibility of hazard changes beyond three years by placing spline knots beyond this point. 

The `basehaz_ops` argument is used to control the spline.  The `bknots` component of this is the vector comprising the lower and upper boundary knots.  Here we simply move the upper boundary knot from three to four years.

```{r,results="hide"}
nd_mod2 <- survextrap(Surv(years, status) ~ 1, data=colons, chains=1, 
                     basehaz_ops = list(bknots = c(0, 4)))
plot(nd_mod2, tmax=5)
```

This increases the amount of uncertainty about the extrapolated survival and hazard.  

There are other ways we could have done this, such as changing the position of the knot, or adding extra knots around or beyond the upper part of the data.   The extrapolations are likely to be sensitive to the choice. 

A sensible guide is to place the upper knot at the latest time that you are interested in modelling.  Beyond this time, you either think the hazard will not change, or any changes in the hazard do not matter for the purpose of the model.

The priors should then be chosen to give a low probability that the hazard varies outside the range thought reasonable, e.g. in terms of orders of magnitude.   The package should provide a nice way to convert beliefs of this kind into priors.

But note that it is only necessary to extrapolate in this way, using knots and default priors, if there is **no substantive information** about the long term hazard!

In many practical situations of extrapolation in time-to-event models, we do have information.   For human survival, we at least know that people do not tend to live much longer than 100 years.  There are usually data from national agencies about mortality of general populations. 

The idea of the package is to make this external information as explicit as possible - ideally in the form of data. 




## Mean and restricted mean survival 

The functions `mean` and `rmst` calculate the mean and restricted mean survival time (RMST) from a fitted model.  Uncertainty is expressed by using the MCMC sample of the model parameters, and calculating the mean (or RMST) for each draw, which produces a sample from the posterior distribution.   The posterior median and credible intervals are computed by summarising this sample.

For particular combinations of parameter values, the mean under the model `nd_mod` cannot be calculated (resulting in an error message about a divergent integral), suggesting there is a substantial posterior probability that the mean is infinite.  

Instead we compute the restricted mean survival time $RMST(t)$ over three alternative time limits $t$: 3, 10 and 1000 years.  The upper 95\% credible limit for $RMST(1000)$ is very large. 
(`niter` controls how many MCMC iterations to use to summarise the distribution - this is artificially reduced here so this example runs faster. In real applications you should check there are enough iterations to get summaries with the amount of precision yoy want - this will usually be 1000 or more)

```{r}
# mean(nd_mod)
rmst(nd_mod2, c(3,10,1000), niter=100)
```

We do not really believe that the mean survival for this population can be this large. 

This is evidence that the fitted model is unrealistic, and we should have included external information to bound the estimates of the mean within plausible values. 

This can be done with external data. 





## Extrapolation using long term population data 

Suppose we judge that after 5 years, the survival of these patients will be the same as in the general population, and we have some data describing the annual survival rates of a population who are similar to this one, perhaps from matching to national statistics or registry data by age and sex.  We would construct it something like this (though fake data are shown here).

```{r,results="hide"}
extdat <- data.frame(start = c(5, 10, 15, 20), 
                     stop =  c(10, 15, 20, 25), 
                     n = c(100, 100, 100, 100), 
                     r = c(50, 40, 30, 20))
nde_mod <- survextrap(Surv(years, status) ~ 1, data=colons, 
                      chains=1, external = extdat)
plot(nde_mod)
```

```{r}
mean(nde_mod, niter=100)
rmst(nde_mod, c(3, 10, 1000), niter=100)
```

Including the external data gives a more confident extrapolation.   The mean is finite.  RMST converges to the mean as it is supposed to. 

At present, not much thought has gone into choice of knot locations with external data.  Currently these knots are based on just concatenating the event times in the individual data with the follow-up times in the external data, and then taking quantiles.   Suggestions are welcome for a smarter approach.   Knots in the middle of follow-up intervals?



## Expert elicitation on the long term

Information about long term survival could be elicited from experts.  To use this information about the model, we should also elicit the expert's _uncertainty_.

For example, we ask the expert to consider a set of people who have survived for 10 years.  How many of them would they expect to survive a further 5 years?  Through some kind of formal elicitation process, they supply a best guess (median) of 30%, and a 95\% credible interval of 10\% to 50\%.  

Using standard techniques from elicitation ([SHELF](http://www.jeremy-oakley.staff.shef.ac.uk/shelf/)) we can interpret that as a $Beta(6.6, 15.0)$ prior distribution for the survival probability.  

```{r}
SHELF::fitdist(vals=c(0.1, 0.3, 0.5), probs=c(0.025, 0.5, 0.975),
               lower=0, upper=1)$Beta
```

We can interpret this as the posterior from having observed $y=6$ survivors out of $n=20$ people (recalling the posterior from a $Binomial(y, n)$ combined with a vague $Beta(0.5, 0.5)$ prior is $Beta(y+0.5, n-y+0.5)$, and rounding $n$ and $y$ to whole numbers).

So the expert's judgment is equivalent to the information in an external dataset of the form 

<table> 
<tr>
<th colspan="2">Follow-up period </th>
<th colspan="2">Number</th>
</tr> 
<tr><th>Start time $t$</th><th>End time $u$</th><th>Alive at $t$</th><th>Still alive at $u$</th></tr>

<tr>
<td> 10 </td>
<td> 15 </td>
<td> 20 </td>
<td> 6  </td>
</tr>
</table>

and we can use it in a `survextrap` model as follows: 
```{r,results="hide"}
extdat <- data.frame(start = c(10), stop =  c(15), 
                     n = c(20), r = c(6))
nde_mod <- survextrap(Surv(years, status) ~ 1, data=colons,
                      chains=1, external = extdat)
plot(nde_mod)
```

```{r}
mean(nde_mod, niter = 100)
```

There is still substantial uncertainty about the mean, even with this level of information, but comparing to the second model above (`nd_mod2`), it is better than no information at all.    More investigation of the role of the knot placement here (blue lines in the figure) might be wise - particularly the one at 15 years.

This approach might be extended to include elicited values from multiple time points, or considering multiple experts.   In each case the elicited information can be converted straightforwardly into an aggregate table for use in `survextrap`.   




## Covariates

`survextrap` uses a proportional hazards model to represent covariates.    In the example here, we model survival by treatment group `rx`, which is a factor with three levels.  First fit a standard Cox model: 

```{r}
coxph(Surv(years, status) ~ rx, data=colons)
```

Then fit a `survextrap` model and extract the log hazard ratios.  These agree with the Cox model - as expected, as we are using a proportional hazards model with a very flexible baseline hazard function.
```{r}
rxph_mod <- survextrap(Surv(years, status) ~ rx, data=colons, chains=1, refresh=0)
summary(rxph_mod) |>
    filter(variable=="loghr")
```

The posterior median survival curves (thick lines) agree with the subgroup-specific Kaplan-Meier estimates (thin lines).
```{r}
plot(rxph_mod, niter=100)
```

Any number of covariates, categorical or continuous, can be included. 

We can also have covariates in the external data.   If covariates are included in the model formula, and an external dataset is supplied, then we must specify covariate values for each row of the external dataset.   (If the covariates are factors, then they can be supplied as character vectors in `external`, but the values should be taken from the factor levels in the internal data [todo: this probably isn't a necessary restriction])

For example, the external data might be assumed to have the same survival as the control group of the trial (corresponding to a value of `"Obs"` for the variable `rx`).

```{r}
extdat <- data.frame(start = c(5, 10), stop =  c(10, 15), 
                     n = c(100, 100), r = c(50, 40), 
                     rx = "Obs")
rxphe_mod <- survextrap(Surv(years, status) ~ rx, data=colons, 
                      chains=1, external = extdat, refresh=0)
rmst(rxphe_mod, niter=100, t=20)
plot(rxphe_mod, niter=100, tmax=5)
plot_hazard(rxphe_mod, niter=100, tmax=20)
```



## Cure models

The package provides a simulated dataset `curedata` with an obvious cure fraction.

The probability of cure for `x=0` is 0.5, and for `x=1` 0.622 (so the log odds ratio is 0.5).   The uncured fraction follows a Weibull(1.5, 1.2) survival distribution.

```{r,results="hide",cache=TRUE}
plot(survfit(Surv(t, status) ~ 1, data=curedata))

noncure_mod <- survextrap(Surv(t, status) ~ 1, data=curedata, chains=1, 
                          cure=FALSE)
plot(noncure_mod) # doesn't quite capture the curve

cure_mod <- survextrap(Surv(t, status) ~ 1, data=curedata, chains=1, cure=TRUE, iter=1000)
plot(cure_mod, tmax=10, niter=20) 
```

Covariates on the cure fraction can be supplied by putting a formula in the `cure` argument.   These will be modelled using logistic regression. 

```{r}
curec_mod <- survextrap(Surv(t, status) ~ 1, data=curedata, cure=~x, fit_method="opt")
summary(curec_mod) %>% 
    filter(variable %in% c("pcure", "logor_cure", "or_cure"))
```

In this summary,  `pcure` is the probability of cure at a value of 0 for the covariate `x.`


## Relative survival models

To implement the standard "additive hazards" model for relative survival, the background hazard can be supplied as a fixed constant alongside the data.     The model used is a variant of the model by [Nelson et al](https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.3064) and should give similar results.  The only difference is that the model in `survextrap` is Bayesian, and a different kind of spline is used.

As an example, suppose the background hazard is 0.05 at all times.  This is appended to the data as an extra column.  The name of this column is supplied (unquoted) as the `backhaz` argument to `survextrap`.

```{r,results="hide"}
colonsb <- colons
colonsb$bh <- rep(0.05, nrow(colons))
modb <- survextrap(Surv(years, status) ~ 1, data=colonsb, backhaz=bh, chains=1)
```

The parameter estimates in the fitted model, and the fitted survival or hazard, then describe the excess hazard for the study population.  That is, the overall hazard minus the background hazard.  

In the example below, the excess hazard from the relative hazard model (with constant background 0.05) is shown in blue below the fitted overall hazard from a model with no background adjustment.  As expected, the excess hazard is around 0.05 less than the overall hazard.

```{r,results="hide"}
mod <- survextrap(Surv(years, status) ~ 1, data=colonsb, chains=1)
library(ggplot2)
plot_hazard(mod) + 
    geom_line(data=hazard(modb), col="blue")
```


An alternative approach to modelling a study population and a background population in `survextrap` would be to estimate the background hazard from external aggregate data supplied as an `external` argument.   If a binary covariate is included which takes a different value between the external data and the study data, then the hazards would be assumed to be proportional between the study population and external population.   The advantage of this approach would be that it could account for uncertainty about the background hazard.   However the assumption of proportional hazards is restrictive.   If the background hazard is not uncertain, then the relative survival model would be preferable, as the excess hazard is modelled flexibly. 
